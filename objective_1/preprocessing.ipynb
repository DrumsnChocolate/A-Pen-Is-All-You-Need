{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "DATA_SET = 'upper_indep'\n",
    "# load data\n",
    "# data = np.load(f'preprocessed/IMWUT_OnHW-chars_dataset_2020-09-22/{DATA_SET}.pkl', allow_pickle=True)\n",
    "# set global variables\n",
    "LOG = True\n",
    "SAMPLE_LENGTH = 64 # resampled to 64 in preprocessing.ipynb\n",
    "N_CHANNELS = 13\n",
    "CLASSES = 54 # in the case of 'both' lower and upper case.\n",
    "if DATA_SET.__contains__('lower') or DATA_SET.__contains__('upper'):\n",
    "    CLASSES = 26 # in the case of 'lower' or 'upper' case.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "MAX_ACC_FRONT = 32768\n",
    "MAX_GYR = 32768\n",
    "MAX_ACC_BACK = 8192\n",
    "MAX_MAG = 8192\n",
    "MAX_FORCE = 4096\n",
    "\n",
    "DESIRED_SAMPLE_LENGTH = SAMPLE_LENGTH\n",
    "\n",
    "def log(o):\n",
    "    if LOG:\n",
    "        print(o)\n",
    "\n",
    "################# util functions #############\n",
    "\n",
    "def remove_empty(xs, ys):\n",
    "    i = 0\n",
    "    while i < len(xs):\n",
    "        x = xs[i]\n",
    "        if len(x) == 0:\n",
    "            xs = np.delete(xs, i)\n",
    "            ys = np.delete(ys, i)\n",
    "            continue\n",
    "        else:\n",
    "            i += 1\n",
    "    return xs, ys\n",
    "\n",
    "def reshape(xs):\n",
    "    for i in range(len(xs)):\n",
    "        # log(xs[i].shape)\n",
    "        xs[i] = np.transpose(xs[i])\n",
    "    return xs\n",
    "        # log(xs[i].shape)\n",
    "    # new_xs = []\n",
    "    # for i in range(len(xs)):\n",
    "    #     channels = []\n",
    "    #     try:\n",
    "    #         xs[i][0]\n",
    "    #     except:\n",
    "    #         log(xs[i])\n",
    "    #     for k in range(len(xs[i][0])):\n",
    "    #       channels.append([])\n",
    "    #     for j in range(len(xs[i])):\n",
    "    #       for k in range(len(xs[i][j])):\n",
    "    #         channels[k].append(xs[i][j][k])\n",
    "    #     new_xs.append([])\n",
    "    #     new_xs[i] = channels\n",
    "    # return new_xs\n",
    "\n",
    "\n",
    "def unreshape(xs):\n",
    "    return reshape(xs)\n",
    "    # old_xs = []\n",
    "    # for i in range(len(xs)):\n",
    "    #     sensors = []\n",
    "    #     for j in range(len(xs[i][0])):\n",
    "    #         sensors.append([])\n",
    "    #     for k in range(len(xs[i])):\n",
    "    #         for j in range(len(xs[i][k])):\n",
    "    #             sensors[j].append(xs[i][k][j])\n",
    "    #     old_xs.append(sensors)\n",
    "    # return old_xs\n",
    "\n",
    "def resample(xs, desired_sample_length):\n",
    "  for i in range(len(xs)):\n",
    "    x = np.arange(0, len(xs[i][0]), len(xs[i][0])/desired_sample_length)[:desired_sample_length]\n",
    "    resampled = []\n",
    "    for k in range(len(xs[i])):\n",
    "      xp = np.arange(0, len(xs[i][k]))\n",
    "      resampled.append(np.interp(x, xp, xs[i][k]))\n",
    "      # xs[i][k] = np.interp(x, xp, xs[i][k])\n",
    "      if len(resampled[k]) != desired_sample_length:\n",
    "          raise ValueError()\n",
    "    resampled = np.array(resampled)\n",
    "    xs[i] = resampled\n",
    "  return xs\n",
    "\n",
    "def reshape_resample_unreshape(xss, desired_sample_length):\n",
    "    reshaped_xss = reshape(xss)\n",
    "    resampled_reshaped_xss = resample(reshaped_xss, desired_sample_length)\n",
    "    unreshaped_resampled_reshaped_xss = unreshape(resampled_reshaped_xss)\n",
    "    return unreshaped_resampled_reshaped_xss\n",
    "\n",
    "def normalize(xs):\n",
    "    for i in range(len(xs)):\n",
    "        xs[i] /= np.array([MAX_ACC_FRONT,\n",
    "                  MAX_ACC_FRONT,\n",
    "                  MAX_ACC_FRONT,\n",
    "                  MAX_ACC_BACK,\n",
    "                  MAX_ACC_BACK,\n",
    "                  MAX_ACC_BACK,\n",
    "                  MAX_GYR/2,\n",
    "                  MAX_GYR/2,\n",
    "                  MAX_GYR/2,\n",
    "                  MAX_MAG/2,\n",
    "                  MAX_MAG/2,\n",
    "                  MAX_MAG/2,\n",
    "                  MAX_FORCE/2]).reshape(1,13)\n",
    "        for j in range(len(xs[i])):\n",
    "            xs[i][j][12] -= 1\n",
    "    return xs\n",
    "\n",
    "def remove_hover(xs):\n",
    "    new_xs = []\n",
    "    for x in xs:\n",
    "        i = 0\n",
    "        while i < len(x) and x[i][12] < 0.2:\n",
    "            i += 1\n",
    "        j = len(x) - 1\n",
    "        while j > 0 and x[j][12] < 0.2:\n",
    "            j -= 1\n",
    "        new_xs.append(x[i:j+1])\n",
    "    return new_xs\n",
    "\n",
    "\n",
    "\n",
    "def resample_normalize_fold(fold):\n",
    "    xtrain, ytrain, xtest, ytest = fold\n",
    "    xtrain, ytrain = remove_empty(xtrain, ytrain)\n",
    "    xtest, ytest = remove_empty(xtest, ytest)\n",
    "    xtrain_resampled = reshape_resample_unreshape(xtrain, DESIRED_SAMPLE_LENGTH)\n",
    "    xtrain_resampled_normalized = normalize(xtrain_resampled)\n",
    "    xtest_resampled = reshape_resample_unreshape(xtest, DESIRED_SAMPLE_LENGTH)\n",
    "    xtest_resampled_normalized = normalize(xtest_resampled)\n",
    "\n",
    "    xtrain = np.array(np.array(xtrain_resampled_normalized).tolist())\n",
    "    xtest = np.array(np.array(xtest_resampled_normalized).tolist())\n",
    "    ytrain = np.array(ytrain)\n",
    "    ytest = np.array(ytest)\n",
    "    return xtrain, ytrain, xtest, ytest\n",
    "\n",
    "def resample_normalize_hoverless_fold(fold):\n",
    "    xtrain, ytrain, xtest, ytest = fold\n",
    "    xtrain, ytrain, xtest, ytest = *remove_empty(xtrain, ytrain), *remove_empty(xtest, ytest)\n",
    "    xtrain = remove_hover(xtrain)\n",
    "    xtest = remove_hover(xtest)\n",
    "    xtrain = reshape_resample_unreshape(xtrain, DESIRED_SAMPLE_LENGTH)\n",
    "    xtest = reshape_resample_unreshape(xtest, DESIRED_SAMPLE_LENGTH)\n",
    "    xtrain = normalize(xtrain)\n",
    "    xtest = normalize(xtest)\n",
    "    xtrain = np.array(np.array(xtrain).tolist())\n",
    "    xtest = np.array(np.array(xtest).tolist())\n",
    "    ytrain = np.array(ytrain)\n",
    "    ytest = np.array(ytest)\n",
    "    return xtrain, ytrain, xtest, ytest\n",
    "\n",
    "\n",
    "def bounds(xs):\n",
    "    maxs = []\n",
    "    mins = []\n",
    "    for k in range(13):\n",
    "        maxs.append(0)\n",
    "        mins.append(0)\n",
    "    for i in range(len(xs)):\n",
    "        # per item\n",
    "        for j in range(len(xs[i])):\n",
    "            # per timestamp\n",
    "            for k in range(13):\n",
    "                x = xs[i][j][k]\n",
    "                if x > maxs[k]:\n",
    "                    maxs[k] = x\n",
    "                if x < mins[k]:\n",
    "                    mins[k] = x\n",
    "    return mins, maxs\n",
    "\n",
    "def log_bounds(xs):\n",
    "    if LOG:\n",
    "        log(f'min and max per channel: {list(zip(*bounds(xs)))}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def find(l, condition):\n",
    "    c = 0\n",
    "    indices = []\n",
    "    for i in range(len(l)):\n",
    "        e = l[i]\n",
    "        if condition(e):\n",
    "            c+=1\n",
    "            indices.append(i)\n",
    "    return indices\n",
    "\n",
    "def resample_normalize(data_set):\n",
    "    with open(f'../IMWUT_OnHW-chars_dataset_2020-09-22/{data_set}.pkl', 'rb') as file:\n",
    "        data = pickle.load(file)\n",
    "    for i in range(len(data)):\n",
    "        data[i] = resample_normalize_fold(data[i])\n",
    "    return data\n",
    "\n",
    "def resample_normalize_hoverless(data_set):\n",
    "    with open(f'../IMWUT_OnHW-chars_dataset_2020-09-22/{data_set}.pkl', 'rb') as file:\n",
    "        data = pickle.load(file)\n",
    "    for i in range(len(data)):\n",
    "        data[i] = resample_normalize_hoverless_fold(data[i])\n",
    "    return data\n",
    "\n",
    "def plot(data, labels, n_ex, n_channels):\n",
    "    if LOG:\n",
    "        plt.figure(figsize=(n_ex*5, 20*n_channels/N_CHANNELS)) # dimensions of the plot in inches\n",
    "        for i in range(n_ex):\n",
    "            channels = [] # sensor channels\n",
    "            for k in range(n_channels):\n",
    "                channels.append([])\n",
    "                for j in range(len(data[i])):\n",
    "                    channels[k].append(data[i][j][k])\n",
    "            for k in range(n_channels):\n",
    "                plt.subplot(n_channels, n_ex, n_ex*k+i+1)\n",
    "                plt.plot(channels[k])\n",
    "            plt.title(labels[i])\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def dump_data(data, data_set):\n",
    "    with open(f'preprocessed/{data_set}.pkl', 'wb') as file:\n",
    "        pickle.dump(data, file)\n",
    "\n",
    "def dump_data_hoverless(data, data_set):\n",
    "    with open(f'preprocessed/hoverless/{data_set}.pkl', 'wb') as file:\n",
    "        pickle.dump(data, file)\n",
    "\n",
    "def preprocess(data_set):\n",
    "    data = resample_normalize(data_set)\n",
    "    dump_data(data,data_set)\n",
    "\n",
    "def preprocess_hoverless(data_set):\n",
    "    data = resample_normalize_hoverless(data_set)\n",
    "    dump_data_hoverless(data, data_set)\n",
    "\n",
    "def preprocess_all():\n",
    "    for data_set in ['both_dep', 'both_indep', 'lower_dep', 'lower_indep', 'upper_dep', 'upper_indep']:\n",
    "    # for data_set in ['both_indep']:\n",
    "        preprocess(data_set)\n",
    "\n",
    "def preprocess_all_hoverless():\n",
    "    for data_set in ['both_dep', 'both_indep', 'lower_dep', 'lower_indep', 'upper_dep', 'upper_indep']:\n",
    "    # for data_set in ['both_indep']:\n",
    "        preprocess_hoverless(data_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "source": [
    "preprocess_all()\n",
    "# preprocess_all_hoverless()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
